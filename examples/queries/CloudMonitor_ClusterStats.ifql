// potential builtins
projectField = (f, table=<-) => filter(table:table, fn: (r) => r._field == f)
projectMeasurement = (m, table=<-) => filter(table:table, fn: (r) => r._measurement == m)
select = (measurement, field, table=<-) => projectMeasurement(m:measurement, table:table) |> projectField(f:field)
withCID = (value, table=<-) => filter(table:table, fn: (r) => r["cluster_id"] == value)



// I don't need these for this set of queries, but I think they would be nice to have
// also they would need to write a custom func in Go
// AnyOf = (table=<-, functions) =>  // filter that returns true if any of the list of input functions is true
// OneOf = (table=<-, functions) => // filter that returns true if exactly one of the input functions is true
// AllOf = (table=<-, functions) => // conjunction of filter functions.

// helper functions //
hostFilter = (table=<-) => filter(table:table, fn: (r) => (r["host"] == "influxmon"))
// could be a built-in but we don't want to get too carried away with compound functions
fromRange = (forDB, forRange) => from(db:forDB) |> range(start:forRange)

// AggregateCPUCluster = (agFn=(table=<-) => table ) =>
//     fromRange(forDB:"telegraf", forRange:-2m)
//       |> select(measurement: "system", field: "n_cpus")
//       //|> withCID(value: CID)
//       |> hostFilter()
//       |> group(by:["host"])
//       |> last()
//       |> group()
//       |> agFn()



// InfluxQL TotalClusterCPU Query:
// SELECT sum("last") from
//   (SELECT last("n_cpus")
//    FROM "telegraf"."default"."system"
//    WHERE time > now() - 2m and cluster_id = :Cluster_Id:
//      AND (host =~ /.*data.*/ OR host =~ /tot-.*-(3|4)/)
//    GROUP BY host)

// TotalClusterCPU = AggregateCPUCluster(agFn: sum)

// InfluxQL NumberOfNodes Query:
// SELECT count("last") from
//   (SELECT last("n_cpus")
//     FROM "telegraf"."default"."system"
//     WHERE time > now() - 2m and cluster_id = :Cluster_Id:
//       AND (host =~ /.*data.*/ OR host =~ /tot-.*-(3|4)/)
//     GROUP BY host)

// NumberOfNodes = AggregateCPUCluster(agFn: count)



// InfluxQL Memory Per Data Node Query:
// SELECT last("max") from
//   (SELECT max("total")/1073741824 FROM
//     "telegraf"."default"."mem"
//     WHERE "cluster_id" = :Cluster_Id:
//      AND time > :dashboardTime:
//      AND (host =~ /.*data.*/ OR host =~ /tot-.*-(3|4)/)
//      GROUP BY :interval:, host)

MemPerDataNode = (DASHTIME, INTERVAL) =>
    fromRange(forDB:"telegraf", forRange:DASHTIME)
      |> select(measurement: "mem", field: "total")
      //|> withCID(value: CID)
      //|> hostfilter()
      |> window(every: INTERVAL)
      |> group(by: ["host"])
      |> max()
      |> map(fn:(r) => r._value / 1073741824)


// InfluxQL Disk Usage Query
// SELECT last("used")/1073741824 AS "used" FROM
//   "telegraf"."default"."disk"
//   WHERE time > :dashboardTime:
//     AND cluster_id = :Cluster_Id:
//     AND (host =~ /.data./ OR host =~ /tot-.*-(3|4)/)
//   FILL(0)

//     // fill seems to be used to return a default value. Not sure how IFQL behaves

DiskUsage = (DASHTIME) =>
    fromRange(forDB:"telegraf", forRange:DASHTIME)
      |> select(measurement: "disk", field: "used")
      //|> withCID(value: CID)
      //|> hostfilter()
      |> last()
      |> map(fn:(r) => r._value / 1073741824)

DiskAllocated = (DASHTIME, INTERVAL) =>
  DiskUsage(DASHTIME:DASHTIME)
    |> window(every:INTERVAL)
    |> last()



//  InfluxQL Percent Availability Query
// SELECT (sum("service_up") / count("service_up"))*100 AS "up_time"
//   FROM "watcher"."autogen"."ping"
//   WHERE cluster_id = :Cluster_Id:
//     AND time > :dashboardTime:
//   FILL(0)


PercentAvailability = (DASHTIME) => {
  serviceUp = (fromRange(forDB:"watcher", forRange: DASHTIME)
      |> select(measurement: "ping", field: "service_up"))
      //|> withCID(value: CID)

  up_time = sum(serviceUp) / count(serviceUp) * 100
  return up_time
}




//  InfluxQL CPU Utilization
// SELECT mean("usage_user") AS "Usage" FROM
//   "telegraf"."default"."cpu"
//   WHERE time > :dashboardTime:
//     AND cluster_id = :Cluster_Id:
//   GROUP BY :interval:,host

AggregateMeasureIntervalGroup = (table=<-, aggFn, measurement, field, interval, gr=["host"]) =>
  table
    |> select(measurement: measurement, field: field)
    |> window(every:interval)
    |> group(by: gr)
    |> mean()

telegrafDashtime =(DASHTIME) => fromRange(forDB: "telegraf", forRange: DASHTIME) 

CPUUsage = (INTERVAL, CID, DASHTIME) =>
    telegrafDashtime(DASHTIME:DASHTIME)
      |> withCID( value: CID)
      |> AggregateMeasureIntervalGroup(aggFn: max, measurement:"cpu", field: "usage_user", interval:INTERVAL, gr:["host"])

//  InfluxQL Memory Usage %
// SELECT mean("used_percent") FROM
//   "telegraf"."default"."mem"
//   WHERE "cluster_id" = :Cluster_Id:
//     AND time > :dashboardTime:
//   GROUP BY :interval:, "host"


MemoryUsage = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME:DASHTIME)
    |> withCID( value: CID)
    |> AggregateMeasureIntervalGroup(aggFn: mean, measurement:"mem", field: "used_percent", interval: INTERVAL, gr: ["host"])

// InfluxQL System Load (Load5)
// SELECT max("load5") AS "Current Load", max("n_cpus") AS "CPUs Allocated"
//   FROM "telegraf"."default"."system"
//   WHERE time > :dashboardTime:
//     AND cluster_id = :Cluster_Id:
//   GROUP BY :interval:, "host"


SystemLoad = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME:DASHTIME)
    |> withCID( value: CID)
    |> map(fn: (r) => ({
          CurrentLoad: AggregateMeasureIntervalGroup(table: r, aggFn: max, measurement: "system", field: "load5", interval: INTERVAL, gr: ["host"]),
          CPUSAllocated: AggregateMeasureIntervalGroup(table: r, aggFn: max, measurement: "system", field: "n_cpus", interval: INTERVAL, gr: ["host"])
       }))



// InfluxQL Container Memory Utilization
// SELECT mean("usage_percent")
//   FROM "telegraf"."default"."docker_container_mem"
//     WHERE "cluster_id" = :Cluster_Id:
//     AND ("container_name" =~ /influxd.*/ OR "container_name" =~ /kap.*/)
//     AND time > :dashboardTime:
//   GROUP BY :interval:, "host", "container_name" fill(null)


ContainerMemoryUtilization = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME:DASHTIME)
    |> withCID( value: CID)
//    |> filter( fn: (r) => (r["container_name"] =~ /influxd.*/  OR r["container_name"] =~ /kap.*/)
    |> window(every: INTERVAL)//, fill: null)
    |> group(by: ["host", "container_name"])



// InfluxQL Queries Executed/Min
// SELECT non_negative_derivative(mean("queriesExecuted"), 60s) AS "Queries Executed" FROM
//   "telegraf"."default"."influxdb_queryExecutor"
//   WHERE "cluster_id" = :Cluster_Id:
//     AND time > :dashboardTime:
//   GROUP BY :interval:, "host" fill(null)

DerivativePerIntervalGroup = (table=<-, INTERVAL, gr=["host"]) =>
   table
   |> window(every: INTERVAL)
   |> group(by: gr)
   |> mean()
   |> derivative(nonNegative: true)


QueriesExecutedPerMin = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME:DASHTIME)
    |> withCID( value: CID)
    |> select(measurement: "influxdb_queryExecutor", field: "queriesExecuted")
    |> DerivativePerIntervalGroup(INTERVAL: INTERVAL, gr: ["host"])

// SELECT non_negative_derivative(mean("queryReq"), 60s) AS "Query"
// FROM "telegraf"."default"."influxdb_httpd"
// WHERE "cluster_id" = :Cluster_Id:
//       AND time > :dashboardTime:
// GROUP BY :interval:, "host"

HTTPRequestsPerMin = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME:DASHTIME)
    |> withCID(value: CID)
    |> select(measurement: "influxdb_httpd", field: "queriesExecuted")
    |> DerivativePerIntervalGroup(INTERVAL: INTERVAL, gr: ["host"])

// SELECT non_negative_derivative(max("pointReq"), 60s)
// FROM "telegraf"."default"."influxdb_write"
// WHERE "cluster_id" = :Cluster_Id:
//       AND time > :dashboardTime:
// GROUP BY :interval:, "host"
PerHostThroughput = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME: DASHTIME)
    |> withCID(value: CID)
    |> select(measurement: "influxdb_write", field: "pointReq")
    |> DerivativePerIntervalGroup(INTERVAL: INTERVAL, gr: ["host"])	


// SELECT max("used_percent")
// FROM "telegraf"."default"."disk"
// WHERE "cluster_id" = :Cluster_Id:
//       AND "path" = '/influxdb/conf'
//       AND time > :dashboardTime:
// GROUP BY :interval:, "host" fill(null)

DiskUtilizationPercent = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME: DASHTIME)
    |> withCID(value: CID)
    |> select(measurement: "disk", field: "used_percent")
    |> filter( fn: (r) => r["path"] == "/influxdb/conf" )
    |> window(every: INTERVAL)
    |> group(by: ["host"])
    |> max()

// SELECT mean("queueBytes")
// FROM "telegraf"."default"."influxdb_hh_processor"
// WHERE "cluster_id" = :Cluster_Id:
//       AND time > :dashboardTime:
// GROUP BY :interval:, "host" fill(0)
HintedHandoffQueueSize = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME: DASHTIME)
    |> withCID(value: CID)
    |> select(measurement: "influxdb_hh_processor", field: "queueBytes")
    |> window(every: INTERVAL)
    |> group(by: ["host"])
    |> mean()

// SELECT non_negative_derivative(max("writeError"), 10s)
// FROM "telegraf"."default"."influxdb_write"
// WHERE "cluster_id" = :Cluster_Id:
//       AND time > :dashboardTime:
// GROUP BY :interval:, "host" fill(null)

ShardWriteErrors = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME: DASHTIME)
    |> withCID(value: CID)
    |> select(measurement: "influxdb_write", field: "pointReq")
    |> DerivativePerIntervalGroup(INTERVAL: INTERVAL, gr: ["host"])

// SELECT mean("HeapInUse")
// FROM "telegraf"."default"."influxdb_runtime"
// WHERE "cluster_id" = :Cluster_Id:
//       AND time > :dashboardTime:
// GROUP BY :interval:, "host" fill(null)
HeapSize = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME: DASHTIME)
    |> withCID(value:CID)
    |> window(every: INTERVAL)
    |> group(by: ["host"])
    |> select(measurement: "influxdb_runtime", field: "HeapInUse")
    |> mean()

// SELECT max("used_percent")
// FROM "telegraf"."default"."disk"
// WHERE "cluster_id" = :Cluster_Id:
//       AND "path" = '/'
//       AND time > :dashboardTime:
// GROUP BY :interval:, "host" fill(null)

RootDirectoryUsedPercent = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME:DASHTIME)
    |> withCID(value:CID)
    |> filter(fn: (r) => r["path"] == "/")
    |> window(every: INTERVAL)
    |> group(by: ["host"])
    |> select(measurement: "disk", field: "used_percent")
    |> max()


// SELECT mean("numSeries") AS "Series Cardinality"
// FROM "telegraf"."default"."influxdb_database"
// WHERE "cluster_id" = :Cluster_Id:
//       AND time > :dashboardTime:
// GROUP BY :interval:, "database" fill(null)

SeriesCardinality = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME: DASHTIME)
    |> withCID(value:CID)
    |> window(every: INTERVAL)
    |> group(by: ["database"])
    |> select(measurement: "influxdb_database", field: "numSeries")
    |> mean()


// SELECT non_negative_derivative(percentile("writeReqDurationNs", 99)) /  non_negative_derivative(max("writeReq")) AS "Write Request"
// FROM "telegraf"."default"."influxdb_httpd"
// WHERE "cluster_id" = :Cluster_Id:
//       AND time > :dashboardTime:
// GROUP BY host, :interval: fill(0)
HTTPRequestDuration = (INTERVAL, CID, DASHTIME) => {
  influxdb_httpd =
    telegrafDashtime(DASHTIME: DASHTIME)
      |> withCID(value:CID)
      |> window(every: INTERVAL)
      |> group(by: ["host"])
      |> filter(fn: (r) => r._measurement == "influxdb_httpd")

  writeReqDurationNs = influxdb_httpd |> filter(fn: (r) => r._field == "writeReqDurationNs") |> percentile(p: 0.99, exact: true) |> derivative(nonNegative: true) |> group()
  writeReq = influxdb_httpd |> filter(fn: (r) => r._field == "writeReq") |> max() |> derivative(nonNegative: true) |> group()

  return join (tables: {reqs:writeReq, duration: writeReqDurationNs}, on: ["host"], fn: (tables) => tables.duration["_value"] / tables.reqs["_value"])
}


// SELECT non_negative_derivative(mean(/.*/),60s)
// FROM "telegraf"."default"."influxdb_cq"
// WHERE "cluster_id" = :Cluster_Id:
//       AND time > :dashboardTime:
// GROUP BY :interval: fill(null)

// NOTE:  dont't have regex to do this correctly. 
CQsPerMinute = (INTERVAL, CID, DASHTIME) =>
  telegrafDashtime(DASHTIME: DASHTIME)
    |> window(every: INTERVAL)
    |> withCID(value:CID)
    |> filter(fn: (r) => r._measurement == "influxdb_cq" )
    |> mean()
    |> derivative(unit:60s)


// Queries to partially satisfy the "cluster stats" cloud dashboard: 

// NOTE: these 2 cause a panic when compiling currently 
// TotalClusterCPU()
// NumberOfNodes()

// MemPerDataNode(DASHTIME: -300h, INTERVAL: 30m)

// DiskUsage(DASHTIME: -200h)

// DiskAllocated(DASHTIME: -200h, INTERVAL: 10s)

// PercentAvailability(DASHTIME:-1000h)

// CPUUsage(INTERVAL: 60s, CID: "influxmon", DASHTIME: -300h)

// MemoryUsage(INTERVAL: 60s, CID: "influxmon", DASHTIME: -300h)

// failed to compile query: error calling function "SystemLoad": error calling function "map": function "max" cannot be resolved
// Seems like we can't resolve functions within the map function?
// SystemLoad(INTERVAL: 60s, CID: "influxmon", DASHTIME: -100h)

// ContainerMemoryUtilization(INTERVAL: 60s, CID: "influxmon", DASHTIME: -100h)

// QueriesExecutedPerMin(INTERVAL: 60s, CID: "influxmon", DASHTIME: -100h)

// HTTPRequestsPerMin(INTERVAL: 60s, CID: "influxmon", DASHTIME: -100h)

// PerHostThroughput(INTERVAL: 60s, CID: "influxmon", DASHTIME: -100h)

// DiskUtilizationPercent(INTERVAL: 60s, CID: "influxmon", DASHTIME: -100h)

// HintedHandoffQueueSize(INTERVAL: 60s, CID: "influxmon", DASHTIME: -100h)

// ShardWriteErrors(INTERVAL: 10s, CID: "influxmon", DASHTIME: -100h)

// HeapSize(INTERVAL: 10s, CID: "influxmon", DASHTIME: -100h)

// RootDirectoryUsedPercent(INTERVAL: 10s, CID: "influxmon", DASHTIME: -100h)

// SeriesCardinality(INTERVAL: 10s, CID: "influxmon", DASHTIME: -1000h)

// failed to create physical plan: cannot remove a branch that has more than one parent
// HTTPRequestDuration(INTERVAL: 10s, CID: "influxmon", DASHTIME: -1000h)

CQsPerMinute(INTERVAL: 10s, CID: "influxmon", DASHTIME: -100h)

